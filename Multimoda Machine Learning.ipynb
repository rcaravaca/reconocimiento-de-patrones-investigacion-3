{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Machine Learning\n",
    "## Ejemplo de uso\n",
    "\n",
    "Uno de los frameworks mas utilizados en Machine Learning es Tensorflow/Keras, el cual tambien puede ser utilizado para analisis multimodal.\n",
    "\n",
    "Este ejemplo es basado en: https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "\n",
    "El problema es de regresion, donde se busca una tendencia en el precio de venta de casa.\n",
    "\n",
    "El dataset utilizado es: https://github.com/emanhamed/Houses-dataset\n",
    "\n",
    "Este dataset incluye datos numéricos/categóricos junto con datos de imágenes para cada una de las 535 casas de ejemplo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente se importan los paquetes necesarios:\n",
    "\n",
    "- _pyimagesearch:_ Para el manejo del dataset\n",
    "- _sklearn:_ Para el manejo de los datos de entrenamiento y prueba\n",
    "- _tensorflow/keras:_ Para el manejo del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyimagesearch import datasets\n",
    "from pyimagesearch import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene el dataset con los features de las casas y las imagenes. se define la intensidad de las imagens en tre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading house attributes...\n",
      "[INFO] loading house images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading house attributes...\")\n",
    "df = datasets.load_house_attributes(\"Houses_Dataset/HousesInfo.txt\")\n",
    "\n",
    "print(\"[INFO] loading house images...\")\n",
    "images = datasets.load_house_images(df, \"Houses_Dataset\")\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace particionamiento del set de datos en training y testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing data...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] processing data...\")\n",
    "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escala el feature \"price\" a su valor maximo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxPrice = trainAttrX[\"price\"].max()\n",
    "trainY = trainAttrX[\"price\"] / maxPrice\n",
    "testY = testAttrX[\"price\"] / maxPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procesan los features de las casas, se hace one-hot encoding en los features categóricas y se concatenan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainAttrX, testAttrX) = datasets.process_house_attributes(df,trainAttrX, testAttrX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea el modelo de red convolucional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the MLP and CNN models\n",
    "mlp = models.create_mlp(trainAttrX.shape[1], regress=False)\n",
    "cnn = models.create_cnn(64, 64, 3, regress=False)\n",
    "\n",
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "# compile the model using mean absolute percentage error as our loss,\n",
    "# implying that we seek to minimize the absolute percentage difference\n",
    "# between our price *predictions* and the *actual prices*\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 87.9984 - val_loss: 71.7051\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 74.3483 - val_loss: 70.2611\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 65.4212 - val_loss: 69.9152\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 63.0343 - val_loss: 64.7282\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 52.0591 - val_loss: 60.8723\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 49.3257 - val_loss: 55.9489\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 48.6011 - val_loss: 50.2104\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 41.1185 - val_loss: 44.3261\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 41ms/step - loss: 39.2347 - val_loss: 40.5564\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 34.7559 - val_loss: 33.3085\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 31.6593 - val_loss: 29.1472\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 28.3193 - val_loss: 27.4081\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 30.3952 - val_loss: 26.2711\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 28.4592 - val_loss: 26.3178\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 24.3804 - val_loss: 24.5550\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 26.1365 - val_loss: 24.9460\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 26.4338 - val_loss: 25.0347\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 26.1647 - val_loss: 24.9885\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 32ms/step - loss: 25.6242 - val_loss: 24.3559\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 25.6612 - val_loss: 24.8274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f55940c8b50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] training model...\")\n",
    "model.fit(x=[trainAttrX, trainImagesX], y=trainY, validation_data=([testAttrX, testImagesX], testY), epochs=20, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una prediccion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] predicting house prices...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] predicting house prices...\")\n",
    "preds = model.predict([testAttrX, testImagesX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula la diferencia entre los precios de vivienda *predichos* y los precios de vivienda *reales*, luego se calcula la diferencia porcentual y la diferencia porcentual absoluta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = preds.flatten() - testY\n",
    "percentDiff = (diff / testY) * 100\n",
    "absPercentDiff = np.abs(percentDiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula la media y la desviación estándar de la diferencia porcentual absoluta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se muestran algunas estadísticas sobre nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] avg. house price: $533,388.27, std house price: $493,403.08\n",
      "[INFO] mean: 39.76%, std: 48.06%\n"
     ]
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\n",
    "print(\"[INFO] avg. house price: {}, std house price: {}\".format(locale.currency(df[\"price\"].mean(), grouping=True),locale.currency(df[\"price\"].std(), grouping=True)))\n",
    "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
